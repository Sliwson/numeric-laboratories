\documentclass{article}

\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{algpseudocode}
\usepackage[inline]{enumitem}
\usepackage{listings}
\usepackage{matlab-prettifier}

\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}

\title{Sprawozdanie \\Metody numeryczne 2 \\\textbf{Temat 1, Zadanie nr 6}}
\date{10/15/2018}
\author{Mateusz Śliwakowski, F4}

\begin{document}
  \pagenumbering{gobble}
  \maketitle
	  \newpage
  \pagenumbering{arabic}
\section{Treść zadania}
\paragraph{}
 Metoda iteracji prostej $SOR$ dla układu \(Ax = b\) z macierzą rozrzedzoną.
\section{Opis metody}

\subsection {Wprowadzenie - metody iteracyjne}
\paragraph{}
Służą do rozwiązywania układów równań liniowych
\[
\left\{ 
\begin{array}{c}
a_{11}x_1+a_{12}x_2+\dots+a_{1n}x_n=b_1 \\ 
a_{21}x_1+a_{22}x_2+\dots+a_{2n}x_n=b_2 \\ 
\vdots\\
a_{n1}x_1+a_{n2}x_2+\dots+a_{nn}x_n=b_n \\ 
\end{array}
\right.
\]
Będziemy je zapisywać w postaci \(Ax = b\) zakładając: \\
\[A=\begin{bmatrix}
  a_{11} & a_{21} & \dots & a_{n1}\\
  a_{21} & a_{22} & \dots & a_{n2}\\
 \vdots & \vdots & \ddots & \vdots \\
  a_{n1} & a_{n2} & \dots & a_{nn}
\end{bmatrix},\hspace{2pt}
 x=\begin{bmatrix}
 x_1\\
 x_2\\
 \vdots\\
 x_n
\end{bmatrix}, \hspace{2pt}
 b=\begin{bmatrix}
 b_1\\
 b_2\\
 \vdots\\
 b_n
\end{bmatrix}\]
\paragraph{}
W metodzie iteracyjnej tworzony jest ciąg kolejnych przybliżeń 
\((x^{(1)}, x^{(2)},\dots)\)
taki, że o ile metoda jest zbieżna \(
\norm{x^{(k)}-x}\xrightarrow{k\rightarrow\infty}0
\).
\paragraph{}
Wiele metod iteracyjnych (w tym metoda $SOR$) ma postać \\ \(x^{(k+1)}=Bx^{(k)}+C\), gdzie \(B\in \mathbb{R}^{n\times n}\), a \(C\in\mathbb{R}^{n}\). Postać $B$ i $C$ definuje konkretną metodę.
\subsection {Metoda $SOR$ (Successive Over-Relaxation)}
\paragraph{}
Zdefiniujmy macierze:
\[
L = \begin{bmatrix}
  0 & 0 & 0 & \dots &0\\
  a_{21} &0 & 0 & \dots & 0\\
  a_{31} & a_{32} &0  & \dots & 0\\
 \vdots & \vdots &\vdots & \ddots & \vdots \\
  a_{n1} & a_{n2} &a_{n3} & \dots & 0
\end{bmatrix},\]
\[
D = \begin{bmatrix}
  a_{11} & 0 & 0 & \dots &0\\
  0 & a_{22} & 0 & \dots & 0\\
  0 & 0  & a_{33} & \dots & 0\\
 \vdots & \vdots &\vdots & \ddots & \vdots \\
  0 & 0 & 0 & \dots & a_{nn}
\end{bmatrix},\]
\[
U = \begin{bmatrix}
  0 & a_{12} & \dots & a_{1n-1} & a_{1n} \\
  0 & 0 & \dots &  a_{2n-1} & a_{2n}\\
 \vdots & \vdots &\ddots & \vdots & \vdots \\
  0 & 0  &\dots &  0 & a_{n-1n}\\
  0 & 0 & 0 & 0 & 0
\end{bmatrix}
 \]
\paragraph{}
Wprowadźmy parametr relaksacji $\omega \in \mathbb{R}$.
Wzór macierzowy metody SOR ma postać:
\[
x^{(k+1)}=\underbrace{(D+\omega L)^{-1}((1-\omega)D-\omega U)}_{B_{SOR}}x^k + \underbrace{(D+ \omega L)^{-1}b\omega}_{C_{SOR}}
\]
Zapis niemacierzowy:
\begin{algorithmic}
\Repeat {
\For {$i=1,\dots,n$}
\State
$x_i^{k+1}=(1-\omega)x_i^{(k)}+\omega(b-
	\sum_{j=1}^{i-1}a_{ij}x_j^{(k+1)}-
	\sum_{j=i+1}^{n}a_{ij}x_j^{(k)}
	)/a_{ii}$
\EndFor
}
\Until{<uzyskamy zbieżność>}
\end{algorithmic}
\paragraph{}
Na potrzeby implementacji zadania posłużymy się zapisem niemacierzowym.

\section{Warunki i założenia}
\begin{enumerate}
\item Macierz wejściowa jest w formacie, który pozwala przyspieszyć obliczenia oraz zmniejszyć złożoność pamięciową dla macierzy rozrzedzonych. Każda kolumna tej macierzy zawiera indeks wiersza, indeks kolumny oraz wartość niezerowego pola macierzy $A$.
\item Diagonala macierzy wejściowej nie może zawierać zerowego elementu (mielibyśmy wtedy dzielenie przez zero). 
\item Aby metoda mogła być zbieżna: $\omega \in (0,2)$ (wniosek z \textit{lematu Kahana})
\item Algorytm może zakończyć się w dwóch przypadkach:
\begin {enumerate}
\item Zostanie spełniony warunek $\norm{x^{(k+1)}-x^{(k)}}<\epsilon$, gdzie $\epsilon$ to zadana\\ dokładność).
\item Przekroczymy maksymalną liczbę iteracji.
\end {enumerate}
\end{enumerate}

\section{Implementacja metody}
\subsection{Funkcja $sorSparse$}
\paragraph{}
Będzie to funkcja, która rozwiązuje zadany problem.
\begin{lstlisting}[style=Matlab-editor]
function [x, k] = sorSparse(A, b, w, xFirst, epsilon, maxIterations)
\end{lstlisting}
\vspace{4pt}
Parametry wejściowe:
\begin{itemize}
\item $A$ - macierz wejściowa w postaci rozrzedzonej (jak w punkcie \textit{Warunki i założenia}),
\item $b$ - wektor wyrazów wolnych,
\item $\omega$ - parametr relaksacji metody $SOR$ (domyślnie 1),
\item $xFirst$ - przybliżenie początkowe (domyślnie wektor złożony z samych jedynek),
\item $epsilon\in \mathbb{R}$ - określa warunek stopu (domyślnie $1\mathrm{e}{-5}$),
\item $maxIterations$ - maksymalna liczba iteracji, jaką może przeprowadzić algorytm (domyślnie $1\mathrm{e}{4}$).
\end{itemize}
Parametry wyjściowe:
\begin{itemize}
\item$x$ - rozwiązanie układu równań liniowych $Ax = b$,
\item$ k$ - liczba iteracji.
\end{itemize}
\paragraph{}
Na początku definiujemy parametry domyślne dla funkcji. Następnie sprawdzamy czy na głównej diagonali nie występuje zero, co uniemożliwiłoby poprawne działanie algorytmu (wystąpiłoby dzielenie przez zero w pętli obliczającej kolejne przybliżenia). W celu ułatwienia dalszej pracy sortujemy tablicę wejściową względem pierwszego wiersza. Definiujemy wektory pomocnicze, określające ile niezerowych wyrazów znajduje się w każdym wierszu macierzy $A$ (nierozrzedzonej) oraz od jakiego indeksu w macierzy w postaci rozrzedzonej rozpoczynają się ciągi wyrazów z kolejnych wierszy. Następnie wykonywana jest pętla główna metody $SOR$, gdzie obliczamy kolejne przybliżenia $x$ do czasu, gdy norma z różnicy kolejnych przybliżeń będzie mniejsza od $epsilon$ lub przekroczymy maksymalną dopuszczalną liczbę iteracji.
\subsection{Pozostałe funkcje}
\paragraph{}
W celu przeprowadzenia testów definiujemy kilka pomocniczych funkcji:
\begin{enumerate}
\item $sorNormal$ - implementacja metody $SOR$ dla macierzy nierozrzedzonej, wprowadzanej w postaci macierzy $n\times n$.
\item $matrixToSparse$ - konwerter macierzy z postaci $n\times n$ na postać opisaną w punkcie \textit{Warunki i założenia}.
\item $generateSquareMatrix$ - elastyczny generator macierzy kwadratowej. Użyjemy go do utworzenia testów od dużym rozmiarze.
\item $displayComparison$ - wyświetla porównanie podanych metod iteracji oraz wbudowanej funkcji Matlaba. Wyświetla czas działania każdej funkcji, porównuje normy z wyników oraz w przypadku metod iteracyjnych wyświetla liczbę wykonanych iteracji.
\end{enumerate}
Skrypty \textit{examples.m} oraz \textit{examplesw.m} zawierają przykłady przedstawione poniżej.
\section{Przykłady i wnioski}
\subsection{Przykłady ze względu na wielkość macierzy}
\paragraph{}
Na początku zobaczymy rezultat działania algorytmu dla macierzy o różnych rozmiarach dla parametru $\omega$ równego $1.25$. Resztę parametrów pozostawimy domyślną, gdyż sprawdzenie wpływu każdego z nich wymagałoby utworzenia zbyt dużej ilości testów. W ramkach przedstawiony zostanie nieznacznie sformatowany wynik działania funkcji $displayComparison$.
\begin{enumerate}
\item Macierz $5 \times 5 $ - jedyna jaką wprowadzimy ręcznie podczas naszych testów:
$$A = \begin{bmatrix}
4 & 0 & 0 & 0 & 3\\
3 & 5 & 0 & 0 & 2\\
0 & 0 & 3 & 0 & 0\\
2 & 0 & 0 & 6 & 0\\
1 & 0 & 0 & 0 & 1
\end{bmatrix}, 
b = \begin{bmatrix}
1\\
2\\
3\\
4\\
5
\end{bmatrix}$$
Otrzymujemy:\\\\
\noindent\fbox{
    \parbox{\textwidth}{
        Metoda $SOR$ dla macierzy rozrzedzonej:\\
		Liczba iteracji: $26$\\
		Czas: $0.21186$\\	
		Zwykła metoda $SOR$:\\
		Liczba iteracji: $26$\\
		Czas: $0.038119$\\
		Wbudowana funkcja Matlaba:
		Czas: $0.046239$\\
		Norma z różnicy wyników metod $SOR$: $0$\\
		Norma z różnicy metody $SOR$ i wbudowanej funkcji Matlaba: $9.9478e-06$
    }
}\\\\
Jak widać nawet d;a macierzy rozrzedzonej małych rozmiarów różnica wydajności pomiędzy metodami $SOR$ jest zauważalna. Obydwie metody uzyskały lepszy wynik również od funkcji Matlaba, lecz warto zauważyć, że uzyskany przez nią wynik jest wynikiem dokładnym.
\item Macierz $25 \times 25$ - wygenerowana automatycznie, $95\%$ elementów to zera, reszta elementów to liczby rzeczywiste. Zaznaczmy, że na diagonali umieszczone są elementy znaczni większe. Wektor wyrazów wolnych również wypełniamy losowo, liczbami z przedziału $(-0.5,0.5)$.\\
\noindent\fbox{
    \parbox{\textwidth}{
        Metoda $SOR$ dla macierzy rozrzedzonej:\\
		Liczba iteracji: $11$\\
		Czas: $0.0043368$\\	
		Zwykła metoda $SOR$:\\
		Liczba iteracji: $11$\\
		Czas: $0.0050096$\\
		Wbudowana funkcja Matlaba:
		Czas: $0.0081887$\\
		Norma z różnicy wyników metod $SOR$: $0$\\
		Norma z różnicy metody $SOR$ i wbudowanej funkcji Matlaba: $1.3348e-06$
    }
}\\\\
Jak widać nawet d;a macierzy rozrzedzonej małych rozmiarów różnica wydajności pomiędzy metodami $SOR$ jest zauważalna. Obydwie metody uzyskały lepszy wynik również od funkcji Matlaba, lecz warto zauważyć, że uzyskany przez nią wynik jest wynikiem z dokładnością maszynową.
\item Macierz $5000 \times 5000$ - wygenerowana automatycznie, $99\%$ elementów to zera. Pozostałe parametry analogicznie jak w punkcie wyżej.\\
\noindent\fbox{
    \parbox{\textwidth}{
        Metoda $SOR$ dla macierzy rozrzedzonej:\\
		Liczba iteracji: $13$\\
		Czas: $0.22015$\\	
		Zwykła metoda $SOR$:\\
		Liczba iteracji: $13$\\
		Czas: $9.6931$\\
		Wbudowana funkcja Matlaba:
		Czas: $0.91442$\\
		Norma z różnicy wyników metod $SOR$: $0$\\
		Norma z różnicy metody $SOR$ i wbudowanej funkcji Matlaba: $1.0588e-06$
    }
}\\\\
W tym przykładzie widać wyraźnie, że dla macierzy rozrzedzonych o dużym rozmiarze funkcja przystosowana do pracy z macierzami tego typu jest zdecydowanie bardziej optymalna. Uzyskany czas jest około 44 razy lepszy niż ten uzyskany przez klasyczną metodę $SOR$. Warto zauważyć że wbudowany algorytm Matlaba znakomicie sobie radzi również z dużymi macierzami - podając wynik z dokładnością maszynową jest zaledwie 4 razy wolniejszy od naszej funkcji.
\item Macierz $100\times 100$ - wygenerowana tak aby suma wartości bezwzględnych znajdujących się na diagonali była mała.\\\\
\noindent\fbox{
    \parbox{\textwidth}{
        Metoda $SOR$ dla macierzy rozrzedzonej:\\
		Metoda jest rozbieżna\\
		Czas: $1.41$\\	
		\vdots
    }
}\\\\
Co nie jest zaskoczeniem - metoda $SOR$ okazała się rozbieżna w tym przypadku.
\end{enumerate}
\subsection{Przykłady ze względu na parametr relaksacji}
Sprawdzimy jaka wartość parametru $\omega$ jest optymalna dla macierzy w różnych rozmiarach. Testować będziemy za pomocą pętli:
\begin{lstlisting}[style=Matlab-editor]
sizes = [5,25,100,500];
for i=1:4
    A = generateSquareMatrix(sizes(i), 0.97, 1, 10, 0);
    b = 0.5 - rand(sizes(i),1);

    A = matrixToSparse(A);

    bestk = 1e5;
    bestw = 0;

    for w=0.02:0.02:1.98
        [x,k] = sorSparse(A,b,w, zeros(sizes(i),1), 10e-8, 10e4);
        if(k < bestk)
            bestk = k;
            bestw = w;
        end
    end

    D = ['Dla rozmiaru: ', int2str(sizes(i)), 'x', int2str(sizes(i)) ' najlepsze w: ', int2str(bestw), ', liczba iteracji: ', int2str(bestk)];
    disp(D);
end
\end{lstlisting}
Otrzymaliśmy wyjście:\\
\noindent\fbox{
    \parbox{\textwidth}{
        Dla rozmiaru: 5x5 najlepsze w: 1, liczba iteracji: 3\\
        Dla rozmiaru: 25x25 najlepsze w: 1, liczba iteracji: 5\\
        Dla rozmiaru: 100x100 najlepsze w: 0.98, liczba iteracji: 8\\
        Dla rozmiaru: 500x500 najlepsze w; 1, liczba iteracji: 10
    }
}\\\\
Okazuję się, że najczęściej, najlepszym wyborem jest $\omega = 1$. Jest to szczególna $\omega$ gdyż wtedy pętla metody $SOR$ przyjmuje taką samą postać, jak metoda Gaussa-Seidela. Aby nie zaciemniać rezultatu działania testu wyciąłem komunikaty o rozbieżności, jednak warto zwrócić uwagę iż dla $\omega$ bliskiej 0 lub 2 metoda potrzebuje dużej ilości iteracji, lub nawet jest rozbieżna.
\subsection{Wnioski}
\begin{enumerate}
\item Na początku warto odpowiedzieć na pytanie: czy warto programować własną metodę, kiedy algorytm Matlaba jest dobrze napisany i dokładnie przetestowany? Jak pokazują przykłady, jeśli nie zależy nam na wysokiej dokładności oraz nasza macierz jest rozrzedzona, własny algorytm potrafi być szybszy od algorytmu Matlaba.
\item Warto zauważyć iż pracując na macierzach przechowywanych w postaci rozrzedzonej ($3\times l$, gdzie l to liczba niezerowych elementów) jesteśmy w stanie przeprowadzać obliczenia na dużo większych macierzach niż bylibyśmy w stanie dla macierzy przechowywanych w tablicach $n \times n$.
\item Pośród testowanych przypadków trudno znaleźć dobre zastosowanie dla samodzielnie napisanej, klasycznej metody $SOR$ - dla dużych macierzy jest ona wolniejsza od funkcji Matlaba nawet o rząd wielkości.
\item Parametr $\omega$ znacząco wpływa na zbieżność. Z przeprowadzonych testów wynika, że najlepiej dla macierzy rozrzedzonych wybierać $\omega \approx 1$.
\end{enumerate}
\end{document}